{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일련의 예측기 (즉, 분류나 회귀 모델)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있다. 일련의 예측기를 ensemble이라고 부르기 때문에 이를 Ensemble learning이라고 한다. 앙상블 학습 알고리즘을 Ensemble method라고 한다.\n",
    "- 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련시킬 수 있다. 예측을 하려면 모든 개별 트리의 예측을 구하면 된다. 그런 다음 가장 많은 선택을 많은(major vote) 클래스를 예측 결과값으로 한다. 결정 트리의 대표적인 ensemble을 Random Forest라고 한다. 간단한 방법이지만 Random Forest는 오늘날 가장 강력한 머신러닝 알고리즘 중 하나이며, 현업에서도 많이 사용된다.\n",
    "- 대표적인 ensemble 기법\n",
    " - Bagging\n",
    " - Boosting\n",
    " - Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Voting based classifier (투표 기반 분류기)\n",
    " - 더 좋은 분류기를 만드는 방법은 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는 것\n",
    " - Hard voting classifier : 다수결 투표로 정해지는 분류기\n",
    "  - 각 개별 분류기(base classifier) 중 가장 뛰어난 것보다도 정확도가 높은 경우가 존재\n",
    "  - Base classifer가 week learner(약한 학습기, 랜덤 추측보다 조금 더 좋은 성능을 내는 분류기)일지라도, 충분하게 많고 다양하다면 strong learner(강한 학습기, 높은 정확도를 내는 분류기)가 될 수 있음\n",
    "  - Law of large numbers(큰 수의 법칙)\n",
    "    - 동전 던지기 예제 : 앞면이 나올 확률이 51%이고 뒷면이 나올 확률이 49%인 동전이 존재한다고 하자. 동전을 1,000번 던졌을 때, 앞면이 다수가 나올 확률은 얼마일까? 이항분포를 사용하면 성공 확률이 51%인 동전을 1,000번 던져서 앞면이 1번만 나올 확률은 $\\frac{1000}{1} \\times 0.51^{1} \\times(1-0.51)^{1000-1}=1.6\\times 10^{-307}$이다. 이런식으로 499까지의 확률을 더하고 1에서 빼면 된다.\n",
    "    - 51% 정확도를 가진 1,000개의 분류기로 앙상블 모델을 구축한다면 75%의 정확도를 기대할 수 있다. (분류기가 완벽하게 독립 & 오차의 상관관계가 없어야 가능)\n",
    "  - Ensemble 방법은 예측기가 가능한 한 서로 독립적일 때 최고의 성능을 발휘. 다양한 분류기를 얻는 한 가지 방법은 **각기 다른 알고리즘으로 학습**시킨다. 이렇게 하면 매우 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 정확도를 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7467502275561786\n",
      "0.9777976478701533\n"
     ]
    }
   ],
   "source": [
    "# 동전 던지기 예제\n",
    "from scipy import stats\n",
    "\n",
    "print(1 - stats.binom.cdf(499, 1000, 0.51))  # 천 번 던졌을 때 앞면이 절반 이상 나올 확률\n",
    "print(1 - stats.binom.cdf(4999, 10000, 0.51))  # 만 번 던졌을 때 앞면이 절반 이상 나올 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skleran에서는 투표 기반 분류기를 `VotingClassifier`로 제공하고, base learner로 서로 다른 모델들을 사용할 수 있도록 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = datasets.make_moons(n_samples=1000, noise=0.3, random_state=42)  # moons data 사용\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hard voting : Base learner의 결과값이 클래스이며, major class를 사용하여 최종 결과를 도출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', logistic), ('rf', rf), ('svm', svm)], voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.896\n",
      "LogisticRegression 0.852\n",
      "SVC 0.912\n",
      "VotingClassifier 0.908\n"
     ]
    }
   ],
   "source": [
    "# 개별 학습기의 성능\n",
    "for clf in (rf, logistic, svm, voting_clf):\n",
    "    clf.fit(train_x, train_y)\n",
    "    test_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, accuracy_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Soft voting : Base learner의 결과값이 확률이며, 각 learner의 확률의 평균을 내어 최종 결과를 도출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42, probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', logistic), ('rf', rf), ('svm', svm)], voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.912\n",
      "LogisticRegression 0.852\n",
      "SVC 0.912\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "# 개별 학습기의 성능\n",
    "for clf in (rf, logistic, svm, voting_clf):\n",
    "    clf.fit(train_x, train_y)\n",
    "    test_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, accuracy_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
